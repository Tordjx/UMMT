{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7ee3bb-7c9c-47e3-ae7f-064be78e7002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from Modele_decodeur_maison import *\n",
    "\n",
    "from Pipeline import *\n",
    "from Trainer import * \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 50\n",
    "\n",
    "# Images\n",
    "# images = np.load(\"C:/Users/lucas/Desktop/train-resnet50-res4frelu.npy\")\n",
    "\n",
    "# Texts\n",
    "tokenized_fr,tokenized_en, vocab_fr,vocab_en = get_train_data_nouveau(batch_size)\n",
    "n_token_fr = len(vocab_fr.keys())\n",
    "n_token_en = len(vocab_en.keys())\n",
    "\n",
    "inv_map_en = {v: k for k, v in vocab_en.items()}\n",
    "inv_map_fr = {v: k for k, v in vocab_fr.items()}\n",
    "\n",
    "n_head = 4 \n",
    "num_encoder_layers = 2\n",
    "num_decoder_layers = 2\n",
    "dim_feedforward = 196\n",
    "dropout = 0.1\n",
    "activation = nn.Softmax\n",
    "embedding_dim = 196\n",
    "\n",
    "model_fr = Modèle(n_token_fr,embedding_dim,n_head, num_encoder_layers,num_decoder_layers,dim_feedforward,dropout,activation).to(device)\n",
    "\n",
    "model_en = Modèle(n_token_en,embedding_dim,n_head, num_encoder_layers,num_decoder_layers,dim_feedforward,dropout,activation).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d493cdfe-c6fe-42b4-9f7a-e89c4df97f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Y=train_auto_encoding(model_fr,tokenized_fr)\n",
    "# Y=train_auto_encoding(model_en,tokenized_en)\n",
    "# Y= cycle_consistency_train(model_fr,model_en,tokenized_fr,tokenized_en)\n",
    "# mixed_train(model_fr,model_en,tokenized_fr,tokenized_en,200,50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "927b652e-793c-439a-9d27-a9a65e88d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def tensor_to_sentence(output,inv_dic):\n",
    "    result = [inv_dic[int(x)] for x in output]\n",
    "    sentence = \"\"\n",
    "    for word in result : \n",
    "        if word == \"DEBUT_DE_PHRASE\" :\n",
    "            pass\n",
    "        elif '@@' in word: \n",
    "            sentence+=word[:-2]\n",
    "        elif word == \"FIN_DE_PHRASE\" :\n",
    "            break \n",
    "        else :\n",
    "            sentence+=word +\" \"\n",
    "    return sentence\n",
    "\n",
    "def traduit(model_A,model_B,data, inv_map):\n",
    "    model_en.eval()\n",
    "    model_fr.eval()\n",
    "    output = torch.argmax(cycle_consistent_forward(model_A,model_B,data),dim = 2).T[j].T\n",
    "    return tensor_to_sentence(output.view(-1),inv_map)\n",
    "\n",
    "i = np.random.randint(len(tokenized_en)//50)\n",
    "j = np.random.randint(50)\n",
    "data,target = get_batch(tokenized_en, i)\n",
    "\n",
    "# print(\"Phrase à traduire : \\n\" + tensor_to_sentence(target.T[j],inv_map_en)+ \"\\n Phrase traduite : \\n \"+ traduit(model_en,model_fr,data, inv_map_fr))\n",
    "\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2604d4a2-4579-4027-a9be-42ba3d74eca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# import s3fs\n",
    "# import pandas\n",
    "# # Create filesystem object\n",
    "# S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "# fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "\n",
    "# val_features  = np.load(fs.open('tordjx/val-resnet50-res4frelu.npy'))\n",
    "# # train_features  = np.load(fs.open('tordjx/train-resnet50-res4frelu.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9aa8adc-c397-4e13-9fe2-4ab3624901fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 50, 196])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text, _  = get_batch(tokenized_fr, 0)\n",
    "val_features = np.load(\"C:/Users/lucas/Desktop/val-resnet50-res4frelu.npy\")\n",
    "batchsz = 50\n",
    "embed = model_fr.embedding(data_text)\n",
    "torch.cat((embed, torch.from_numpy(val_features.reshape(1014,1024,196)[:1000].reshape(1000//batchsz ,1024,batchsz , 196)[0]).to(device))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5281b3cf-9cb7-44ca-958d-00e9e9a67894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "output = model_fr(data_text, True, torch.from_numpy(val_features.reshape(1014,1024,196)[:1000].reshape(1000//batchsz ,1024,batchsz , 196)[0]).to(device= device, dtype = torch.float32)).shape\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff30c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7630,  3.8553, -0.4757,  ..., -2.2199,  1.2233,  1.8430],\n",
       "         [ 2.3845,  3.6675, -0.7584,  ..., -0.9987,  1.6877,  2.0335],\n",
       "         [ 2.1927,  3.5167, -0.4083,  ..., -1.5492,  2.0718,  1.3340],\n",
       "         ...,\n",
       "         [ 1.6823,  3.7639, -1.8769,  ..., -1.2514,  1.5931,  0.1865],\n",
       "         [ 1.2443,  3.5844,  0.0999,  ..., -1.5509,  0.5606,  1.7181],\n",
       "         [ 1.6041,  4.2583, -0.6808,  ..., -2.0061,  1.4375,  1.5468]],\n",
       "\n",
       "        [[ 2.9314,  0.8944,  0.5131,  ..., -1.2942, -0.7042, -0.5976],\n",
       "         [ 1.7710, -0.0852,  0.6356,  ..., -2.8037, -0.2965, -0.5786],\n",
       "         [ 0.7260,  0.0926,  1.6426,  ..., -3.8346, -0.2791, -0.1131],\n",
       "         ...,\n",
       "         [ 1.6280,  1.3521,  0.4833,  ..., -3.4996, -0.8277, -0.9370],\n",
       "         [ 2.5822,  0.7188,  1.4001,  ..., -2.5912,  0.5884, -0.6457],\n",
       "         [ 2.1487,  1.6612,  0.4386,  ..., -2.6689, -0.6266,  0.6099]],\n",
       "\n",
       "        [[ 1.8194, -1.0189, -0.0325,  ..., -2.1817,  0.1767,  2.1091],\n",
       "         [ 2.7374, -1.1626, -0.0885,  ..., -2.9933, -0.9543,  0.2675],\n",
       "         [ 1.3480, -1.9202,  1.6956,  ..., -2.8885,  0.9130, -1.7417],\n",
       "         ...,\n",
       "         [ 1.7750, -0.4085,  0.0105,  ..., -1.5174, -0.3695, -0.9245],\n",
       "         [ 2.6388,  0.0527,  1.0478,  ..., -2.6065,  1.0854,  1.0014],\n",
       "         [ 1.7883, -1.9009, -0.8465,  ..., -0.9479, -0.6821,  0.3432]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.6923,  1.4345,  1.0288,  ..., -1.9853, -1.4201, -1.7455],\n",
       "         [ 1.5896,  1.4812, -0.1403,  ..., -1.2966, -2.3005, -1.9073],\n",
       "         [ 2.0341,  1.8441, -0.2025,  ..., -1.4894, -2.3547, -1.5685],\n",
       "         ...,\n",
       "         [ 1.3063,  0.7547,  0.4691,  ..., -1.7736, -2.2765, -1.9864],\n",
       "         [ 0.5470,  1.2332,  0.4080,  ..., -1.5609, -3.0994, -2.5542],\n",
       "         [ 2.0811,  1.9579, -0.0470,  ..., -2.2036, -2.0647, -1.7418]],\n",
       "\n",
       "        [[ 0.2079,  1.8785,  0.7588,  ..., -1.6061, -2.1684, -1.5985],\n",
       "         [ 1.4625,  1.6019,  0.4601,  ..., -1.7104, -1.4509, -1.5671],\n",
       "         [-0.2708,  1.9716,  0.8534,  ..., -2.1059, -2.4458, -1.7791],\n",
       "         ...,\n",
       "         [ 1.5051,  1.2286,  1.0617,  ..., -1.4395, -1.9565, -1.8502],\n",
       "         [ 1.6626,  1.8801, -0.3434,  ..., -1.7989, -1.7617, -1.3326],\n",
       "         [ 1.2388,  1.7169,  0.3180,  ..., -2.0692, -1.7699, -1.6870]],\n",
       "\n",
       "        [[ 2.1000,  2.4448,  0.7801,  ..., -1.1483, -2.5812, -1.9671],\n",
       "         [ 1.7191,  1.5555,  0.4345,  ..., -1.3880, -1.0913, -1.0959],\n",
       "         [ 1.6004,  3.1439,  1.2058,  ..., -1.3161, -3.0564, -1.2862],\n",
       "         ...,\n",
       "         [ 0.7143,  2.1873,  0.7676,  ..., -2.0657, -2.3243, -1.5075],\n",
       "         [ 1.1091,  2.0837,  0.5793,  ..., -1.5138, -2.7881, -2.0970],\n",
       "         [ 1.8824,  2.1041,  0.6636,  ..., -2.0932, -2.9658, -1.7114]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_fr(data_text, True, torch.from_numpy(val_features.reshape(1014,1024,196)[:1000].reshape(1000//batchsz ,1024,batchsz , 196)[0]).to(device= device, dtype = torch.float32))\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
