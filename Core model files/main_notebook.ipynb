{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb10bae-68df-4d91-9e10-2cecaf169e71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/mamba/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (1.24.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "#mc cp s3/tordjx ummt --recursive\n",
    "# watch -n 0.5 nvidia-smi\n",
    "IL Y A UNE FUITE DE GRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7ee3bb-7c9c-47e3-ae7f-064be78e7002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "from Modele_decodeur_maison import *\n",
    "from Pipeline import *\n",
    "from Trainer import * \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 64\n",
    "\n",
    "# Texts\n",
    "tokenized_fr,tokenized_en, vocab_fr,vocab_en = get_train_data_nouveau(batch_size)\n",
    "#Data non batchés\n",
    "n_token_fr = len(vocab_fr.keys())\n",
    "n_token_en = len(vocab_en.keys())\n",
    "\n",
    "inv_map_en = {v: k for k, v in vocab_en.items()}\n",
    "inv_map_fr = {v: k for k, v in vocab_fr.items()}\n",
    "\n",
    "n_head = 16\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 4096\n",
    "dropout = 0.1\n",
    "activation = nn.Softmax(dim=2)\n",
    "embedding_dim = 1024\n",
    "\n",
    "model_fr = Modèle(n_token_fr,embedding_dim,n_head, num_encoder_layers,num_decoder_layers,dim_feedforward,dropout,activation,vocab_fr[\"TOKEN_VIDE\"],vocab_fr[\"DEBUT_DE_PHRASE\"],vocab_fr[\"FIN_DE_PHRASE\"]).to(device)\n",
    "model_en = Modèle(n_token_en,embedding_dim,n_head, num_encoder_layers,num_decoder_layers,dim_feedforward,dropout,activation,vocab_en[\"TOKEN_VIDE\"],vocab_en[\"DEBUT_DE_PHRASE\"],vocab_en[\"FIN_DE_PHRASE\"]).to(device)\n",
    "\n",
    "#IF WE WANT TO LOAD PREVIOUSLY TRAINED MODEL\n",
    "# model_en.load_state_dict(torch.load(\"tordjx/model_en\"))\n",
    "# model_fr.load_state_dict(torch.load(\"tordjx/model_fr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2604d4a2-4579-4027-a9be-42ba3d74eca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_features  = np.load(fs.open('tordjx/val-resnet50-res4frelu.npy'))\n",
    "# train_features  = np.load(fs.open('tordjx/train-resnet50-res4frelu.npy'))\n",
    "# val_features = np.load(\"C:/Users/lucas/Desktop/val-resnet50-res4frelu.npy\")\n",
    "# val_features = np.load(\"C:/Users/lucas/Desktop/val-resnet50-res4frelu.npy\")\n",
    "train_features  = np.load(\"tordjx/train-resnet50-res4frelu.npy\")\n",
    "val_features = np.load(\"tordjx/val-resnet50-res4frelu.npy\")\n",
    "train_features = torch.from_numpy(train_features)\n",
    "val_features = torch.from_numpy(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201a7586-6ea6-4f1c-8aba-ba2cf389e367",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 1.680535GB\n",
      "torch.cuda.memory_reserved: 1.730469GB\n",
      "torch.cuda.max_memory_reserved: 1.730469GB\n"
     ]
    }
   ],
   "source": [
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d493cdfe-c6fe-42b4-9f7a-e89c4df97f76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.10/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched src_key_padding_mask and src_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/opt/mamba/lib/python3.10/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/opt/mamba/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Error detected in AddmmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/opt/mamba/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/mamba/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/mamba/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/mamba/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/mamba/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_797/2070558845.py\", line 3, in <module>\n",
      "    mixed_train(model_fr,model_en,train_data_fr,train_data_en,500,batch_size, True,[1/2,1])\n",
      "  File \"/home/onyxia/work/ummt/Core model files/Trainer.py\", line 221, in mixed_train\n",
      "    loss = cycle_consistency_train(model_A,model_B,train_data,image_bool)\n",
      "  File \"/home/onyxia/work/ummt/Core model files/Trainer.py\", line 148, in cycle_consistency_train\n",
      "    output = cycle_consistent_forward(model_B,model_A, first_output, features, image_bool)\n",
      "  File \"/home/onyxia/work/ummt/Core model files/Trainer.py\", line 59, in cycle_consistent_forward\n",
      "    return model_B.output_layer(output)\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train_data_fr \u001b[38;5;241m=\u001b[39m [tokenized_fr, train_features]\n\u001b[1;32m      2\u001b[0m train_data_en \u001b[38;5;241m=\u001b[39m [tokenized_en, train_features]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmixed_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_fr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data_fr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data_en\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/ummt/Core model files/Trainer.py:221\u001b[0m, in \u001b[0;36mmixed_train\u001b[0;34m(model_fr, model_en, train_data_fr, train_data_en, n_iter, batch_size, image_bool, repartition)\u001b[0m\n\u001b[1;32m    219\u001b[0m     model_A\u001b[38;5;241m.\u001b[39mloss_list\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m V \u001b[38;5;241m<\u001b[39m repartition[\u001b[38;5;241m1\u001b[39m]  :\u001b[38;5;66;03m#CYCLE CONSISTENT\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcycle_consistency_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_bool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     model_A\u001b[38;5;241m.\u001b[39mloss_list\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m    223\u001b[0m     model_B\u001b[38;5;241m.\u001b[39mloss_list\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m~/work/ummt/Core model files/Trainer.py:174\u001b[0m, in \u001b[0;36mcycle_consistency_train\u001b[0;34m(model_A, model_B, train_data, image_bool)\u001b[0m\n\u001b[1;32m    163\u001b[0m model_B\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# for name,param in model_A.named_parameters():\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m#     if param.grad is not None : \u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m#         gradient_list.append(param.grad)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# with open('mypicklefile', 'wb') as f1:\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m#     pickle.dump(gradient_list, f1)\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m \u001b[43mloss_A\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model_A\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m    176\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model_B\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "train_data_fr = [tokenized_fr, train_features]\n",
    "train_data_en = [tokenized_en, train_features]\n",
    "mixed_train(model_fr,model_en,train_data_fr,train_data_en,500,batch_size, True,[1/2,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033da8a6-1d98-4eea-be9a-ba67221f6780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def moving_average(a, n=1) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "plt.plot(moving_average(model_fr.loss_list))\n",
    "plt.plot(moving_average(model_en.loss_list))\n",
    "# plt.plot(model_en.loss_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af80f3d-53f1-4fe7-9aa1-1868350791a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model_fr.state_dict(), \"tordjx/model_fr\")\n",
    "torch.save(model_en.state_dict(), \"tordjx/model_en\")\n",
    "import os\n",
    "import s3fs\n",
    "!pip install pandas\n",
    "import pandas\n",
    "# Create filesystem object\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "fs.upload(\"tordjx/model_fr\",\"tordjx/model_fr\")\n",
    "fs.upload(\"tordjx/model_en\",\"tordjx/model_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927b652e-793c-439a-9d27-a9a65e88d9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "train_data_fr = [tokenized_fr, train_features]\n",
    "train_data_en = [tokenized_en, train_features]\n",
    "def tensor_to_sentence(output,inv_dic):\n",
    "    result = [inv_dic[int(x)] for x in output]\n",
    "    sentence = \"\"\n",
    "    for word in result : \n",
    "        if word == \"DEBUT_DE_PHRASE\" :\n",
    "            pass\n",
    "        elif '@@' in word: \n",
    "            sentence+=word[:-2]\n",
    "        elif word == \"FIN_DE_PHRASE\" :\n",
    "            break \n",
    "        \n",
    "        else :\n",
    "            sentence+=word +\" \"\n",
    "    return sentence\n",
    "\n",
    "def traduit(model_A,model_B,data, inv_map,image_bool):\n",
    "    model_en.eval()\n",
    "    model_fr.eval()\n",
    "    if image_bool : \n",
    "        data,features= data\n",
    "    output = torch.argmax(cycle_consistent_forward(model_A,model_B,data,features, True),dim = 2)[j]\n",
    "    return tensor_to_sentence(output.view(-1),inv_map)\n",
    "\n",
    "\n",
    "\n",
    "def donne_random():\n",
    "    i = np.random.randint(len(tokenized_en)//batch_size)\n",
    "    j = np.random.randint(batch_size)\n",
    "    batched_data=batchify(train_data_en,batch_size,True)\n",
    "    data,features = batched_data\n",
    "    return data[i],features[i]\n",
    "\n",
    "text,features = donne_random()\n",
    "features = features.to(device,dtype=torch.float32)\n",
    "data = [text,features]\n",
    "for i in range(10):\n",
    "    j = np.random.randint(batch_size)\n",
    "    print(\"Phrase à traduire : \\n\" + tensor_to_sentence(text[j],inv_map_en)+ \"\\n Phrase traduite : \\n \"+ traduit(model_en,model_fr,data, inv_map_fr,True))\n",
    "\n",
    "\n",
    "#%%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
