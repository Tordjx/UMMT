{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686baf3-aca7-422b-81a7-ec7c1c776dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7ee3bb-7c9c-47e3-ae7f-064be78e7002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUT_DE_PHRASE\n",
      "FIN_DE_PHRASE\n",
      "TOKEN_VIDE\n",
      "&@@\n",
      "j\n",
      ";@@\n",
      "DEBUT_DE_PHRASE\n",
      "FIN_DE_PHRASE\n",
      "TOKEN_VIDE\n",
      "&@@\n",
      "j\n",
      "ë\n",
      "ë@@\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from Modele_decodeur_maison import *\n",
    "\n",
    "from Pipeline import *\n",
    "from Trainer import * \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 50\n",
    "\n",
    "# Images\n",
    "# images = np.load(\"C:/Users/lucas/Desktop/train-resnet50-res4frelu.npy\")\n",
    "\n",
    "# Texts\n",
    "tokenized_fr,tokenized_en, vocab_fr,vocab_en = get_train_data_nouveau(batch_size)\n",
    "n_token_fr = len(vocab_fr.keys())\n",
    "n_token_en = len(vocab_en.keys())\n",
    "\n",
    "inv_map_en = {v: k for k, v in vocab_en.items()}\n",
    "inv_map_fr = {v: k for k, v in vocab_fr.items()}\n",
    "\n",
    "n_head = 4 \n",
    "num_encoder_layers = 2\n",
    "num_decoder_layers = 2\n",
    "dim_feedforward = 196\n",
    "dropout = 0.1\n",
    "activation = nn.Softmax\n",
    "embedding_dim = 196\n",
    "\n",
    "model_fr = Modèle(n_token_fr,embedding_dim,n_head, num_encoder_layers,num_decoder_layers,dim_feedforward,dropout,activation).to(device)\n",
    "\n",
    "model_en = Modèle(n_token_en,embedding_dim,n_head, num_encoder_layers,num_decoder_layers,dim_feedforward,dropout,activation).to(device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493cdfe-c6fe-42b4-9f7a-e89c4df97f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Y=train_auto_encoding(model_fr,tokenized_fr)\n",
    "# Y=train_auto_encoding(model_en,tokenized_en)\n",
    "# Y= cycle_consistency_train(model_fr,model_en,tokenized_fr,tokenized_en)\n",
    "# mixed_train(model_fr,model_en,tokenized_fr,tokenized_en,200,50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "927b652e-793c-439a-9d27-a9a65e88d9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase à traduire : \n",
      "a happy young boy sits in a chair with a large elmo doll . \n",
      " Phrase traduite : \n",
      " casino attend es ongles chevauche équipmoyen tirent perron argile moyen soigneusement antiperron attend perron es perron planche tranquille ongles mières fluoreannperron polo médecins médecins médecins médecins médecins solo envotwister twister médecins médecins médecins médecins èque èque èque èque èque èque èque médecins médecins médecins médecins médecins las las las médecins médecins médecins médecins envoenvoenvoenvoestomac estomac estomac envoenvogueugueumédecins médecins médecins estomac estomac estomac estomac estomac estomac las las gueugueugueugueuèque èque tronc tronc tronc tronc tronc envoenvoenvoenvoenvoéquilibre \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8621/3639088073.py:19: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
      "  output = torch.argmax(cycle_consistent_forward(model_A,model_B,data),dim = 2).T[j].T\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "def tensor_to_sentence(output,inv_dic):\n",
    "    result = [inv_dic[int(x)] for x in output]\n",
    "    sentence = \"\"\n",
    "    for word in result : \n",
    "        if word == \"DEBUT_DE_PHRASE\" :\n",
    "            pass\n",
    "        elif '@@' in word: \n",
    "            sentence+=word[:-2]\n",
    "        elif word == \"FIN_DE_PHRASE\" :\n",
    "            break \n",
    "        else :\n",
    "            sentence+=word +\" \"\n",
    "    return sentence\n",
    "\n",
    "def traduit(model_A,model_B,data, inv_map):\n",
    "    model_en.eval()\n",
    "    model_fr.eval()\n",
    "    output = torch.argmax(cycle_consistent_forward(model_A,model_B,data),dim = 2).T[j].T\n",
    "    return tensor_to_sentence(output.view(-1),inv_map)\n",
    "\n",
    "i = np.random.randint(len(tokenized_en)//50)\n",
    "j = np.random.randint(50)\n",
    "data,target = get_batch(tokenized_en, i)\n",
    "\n",
    "print(\"Phrase à traduire : \\n\" + tensor_to_sentence(target.T[j],inv_map_en)+ \"\\n Phrase traduite : \\n \"+ traduit(model_en,model_fr,data, inv_map_fr))\n",
    "\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2604d4a2-4579-4027-a9be-42ba3d74eca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import s3fs\n",
    "import pandas\n",
    "# Create filesystem object\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "\n",
    "val_features  = np.load(fs.open('tordjx/val-resnet50-res4frelu.npy'))\n",
    "# train_features  = np.load(fs.open('tordjx/train-resnet50-res4frelu.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9aa8adc-c397-4e13-9fe2-4ab3624901fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1121, 50, 196])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text, _  = get_batch(tokenized_fr, 0)\n",
    "batchsz = 50\n",
    "embed = model_fr.embedding(data_text)\n",
    "torch.cat((embed, torch.from_numpy(val_features.reshape(1014,1024,196)[:1000].reshape(1000//batchsz ,1024,batchsz , 196)[0]).to(device))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5281b3cf-9cb7-44ca-958d-00e9e9a67894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([97, 50, 196]) torch.Size([1024, 50, 196])\n",
      "tensor([[[ 0.7049,  0.8399,  0.9887,  ..., -2.1492, -0.0053,  1.8226],\n",
      "         [ 0.3827, -0.1423,  0.4637,  ..., -1.8663, -0.3090,  1.6264],\n",
      "         [ 0.4837,  0.7676,  0.4224,  ..., -1.3742, -0.2670,  1.6772],\n",
      "         ...,\n",
      "         [ 0.4163,  0.6139,  0.7413,  ..., -1.8274, -0.2884,  1.7489],\n",
      "         [-0.2638,  1.0282,  1.0514,  ..., -1.6033,  0.3842,  2.4883],\n",
      "         [-0.2210,  0.9907,  0.6721,  ..., -1.7667,  0.4140,  1.7915]],\n",
      "\n",
      "        [[-0.4685,  0.7395,  0.2914,  ...,  0.1102,  0.2189, -0.8870],\n",
      "         [-0.4287,  0.5639, -0.9865,  ..., -1.0535,  0.5909, -0.6768],\n",
      "         [-1.0402,  0.3018,  1.2465,  ..., -0.6023,  0.4301,  0.8055],\n",
      "         ...,\n",
      "         [-0.7018, -0.4500,  2.2858,  ..., -0.3024, -0.0880,  0.5852],\n",
      "         [-0.1163, -0.3267,  0.3846,  ..., -2.8438, -0.1126, -0.2534],\n",
      "         [-0.6118,  0.1725,  2.8546,  ...,  0.5841,  0.3889,  0.7734]],\n",
      "\n",
      "        [[-1.6710,  0.1333,  0.6920,  ...,  0.5399,  0.3211,  0.9147],\n",
      "         [ 0.1459,  0.3971,  1.0924,  ..., -0.8594, -1.2453, -1.3900],\n",
      "         [-0.8387, -2.3047, -1.5467,  ..., -0.9615,  0.0479,  0.2591],\n",
      "         ...,\n",
      "         [ 0.0141, -1.2827,  2.3100,  ...,  0.1205,  2.6587,  0.8930],\n",
      "         [ 0.3342,  0.0069,  0.6134,  ..., -3.0220, -0.8093,  2.1623],\n",
      "         [-1.7218, -1.2623,  0.8420,  ..., -2.4856, -0.5293, -1.1222]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.8219,  0.9422, -0.9696,  ..., -0.7733, -0.3190,  1.8387],\n",
      "         [-2.6508,  1.0266, -0.9319,  ..., -0.7534,  0.1636,  1.5084],\n",
      "         [-2.2286, -0.1813, -0.8752,  ..., -0.2959, -0.0897,  1.7437],\n",
      "         ...,\n",
      "         [-2.1606,  1.2916, -0.9148,  ..., -1.1849, -0.0511,  1.6133],\n",
      "         [-1.9867,  1.3261, -1.2720,  ..., -0.4436, -0.1018,  2.0180],\n",
      "         [-2.1302,  1.0685, -1.1662,  ..., -0.2892,  0.0113,  1.8089]],\n",
      "\n",
      "        [[-1.6399,  1.1227,  0.2026,  ..., -0.7981, -0.2940,  1.3433],\n",
      "         [-1.8892,  1.1736, -1.0787,  ..., -0.6886, -0.0081,  1.6629],\n",
      "         [-1.6800,  1.0371, -1.3062,  ..., -0.4672,  0.0631,  1.6598],\n",
      "         ...,\n",
      "         [-1.5816,  1.2542, -0.9419,  ..., -0.8098, -0.4089,  1.4209],\n",
      "         [-1.7057,  0.9065, -0.9220,  ..., -1.0505, -0.0710,  1.4123],\n",
      "         [-2.0495,  1.0949, -1.3149,  ..., -0.4899,  0.0243,  2.1293]],\n",
      "\n",
      "        [[-1.4669,  0.7358, -0.8128,  ..., -0.2897,  0.0048,  1.5425],\n",
      "         [-1.4446,  0.8196, -0.6860,  ..., -0.3737, -0.1471,  1.7707],\n",
      "         [-1.7519,  0.6068, -0.7018,  ..., -1.5803, -0.0122,  1.6439],\n",
      "         ...,\n",
      "         [-1.9247,  0.3089, -0.6946,  ..., -0.3961, -0.4190,  2.3232],\n",
      "         [-1.4314,  0.7465, -1.0397,  ..., -0.5196,  0.0526,  1.7442],\n",
      "         [-1.1178,  0.2456, -0.8783,  ...,  0.0467,  0.1211,  1.7848]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>) tensor([[[ 0.0149, -0.0982, -0.6073,  ...,  0.1234, -0.3764, -0.2805],\n",
      "         [-0.0437, -0.0123, -0.4650,  ...,  0.2167, -0.2359, -0.2346],\n",
      "         [-0.0734, -0.0125, -0.6586,  ...,  0.0000, -0.3140, -0.2740],\n",
      "         ...,\n",
      "         [ 0.0281, -0.0741, -0.5913,  ...,  0.2210, -0.1643, -0.1587],\n",
      "         [ 0.0121, -0.0498, -0.4128,  ...,  0.2703, -0.2451, -0.2282],\n",
      "         [ 0.0490, -0.0447, -0.0000,  ...,  0.2637, -0.2050, -0.0000]],\n",
      "\n",
      "        [[ 0.0000, -0.1132, -0.6605,  ...,  0.1504, -0.3840, -0.2734],\n",
      "         [ 0.0359,  0.0283, -0.5204,  ...,  0.2490, -0.1762, -0.2154],\n",
      "         [-0.0000, -0.0358, -0.6817,  ...,  0.1136, -0.3297, -0.0000],\n",
      "         ...,\n",
      "         [ 0.0161, -0.0221, -0.6731,  ...,  0.2139, -0.1393, -0.1073],\n",
      "         [ 0.0123, -0.0597, -0.4539,  ...,  0.2733, -0.2275, -0.2190],\n",
      "         [ 0.0000,  0.0079, -0.6128,  ...,  0.2403, -0.1287, -0.1553]],\n",
      "\n",
      "        [[ 0.0000, -0.1084, -0.0000,  ...,  0.1296, -0.3755, -0.2703],\n",
      "         [ 0.0183, -0.0183, -0.0000,  ...,  0.1757, -0.1741, -0.2337],\n",
      "         [-0.0235, -0.0702, -0.7053,  ...,  0.0822, -0.2826, -0.2446],\n",
      "         ...,\n",
      "         [ 0.0407, -0.0437, -0.5666,  ...,  0.2227, -0.1268, -0.1283],\n",
      "         [ 0.0580, -0.0859, -0.0000,  ...,  0.2047, -0.2486, -0.2446],\n",
      "         [ 0.1081,  0.0308, -0.0000,  ...,  0.2796, -0.2469, -0.1854]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0300, -0.0847, -0.7148,  ...,  0.1089, -0.3512, -0.2556],\n",
      "         [-0.0240,  0.0160, -0.5975,  ...,  0.1874, -0.0000, -0.2247],\n",
      "         [ 0.0009, -0.0012, -0.7625,  ...,  0.1306, -0.2405, -0.2098],\n",
      "         ...,\n",
      "         [-0.0688, -0.0324, -0.6512,  ...,  0.2356, -0.1857, -0.1140],\n",
      "         [ 0.0299, -0.0462, -0.5453,  ...,  0.2759, -0.1825, -0.1987],\n",
      "         [ 0.0583, -0.0377, -0.5554,  ...,  0.2955, -0.1310, -0.1862]],\n",
      "\n",
      "        [[ 0.0498, -0.0000, -0.6930,  ...,  0.1117, -0.3242, -0.2420],\n",
      "         [-0.0187, -0.0138, -0.5611,  ...,  0.1706, -0.1951, -0.2194],\n",
      "         [ 0.0084,  0.0000, -0.7379,  ...,  0.1178, -0.2631, -0.2204],\n",
      "         ...,\n",
      "         [-0.0242, -0.0233, -0.6031,  ...,  0.2426, -0.1585, -0.0727],\n",
      "         [ 0.0000, -0.0654, -0.5503,  ...,  0.2403, -0.1972, -0.2301],\n",
      "         [ 0.0546, -0.0187, -0.5975,  ...,  0.3122, -0.1683, -0.1758]],\n",
      "\n",
      "        [[ 0.0219, -0.1013, -0.6939,  ...,  0.0649, -0.2726, -0.2824],\n",
      "         [-0.0409, -0.0079, -0.5510,  ...,  0.1668, -0.2077, -0.2497],\n",
      "         [ 0.0369, -0.0270, -0.7319,  ...,  0.0000, -0.1889, -0.2500],\n",
      "         ...,\n",
      "         [-0.0223, -0.0153, -0.6521,  ...,  0.2245, -0.2053, -0.1142],\n",
      "         [ 0.0511, -0.0618, -0.5072,  ...,  0.2547, -0.1716, -0.2529],\n",
      "         [ 0.0950, -0.0556, -0.5748,  ...,  0.0000, -0.1686, -0.1745]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>) [tensor([[[ 0.7049,  0.8399,  0.9887,  ..., -2.1492, -0.0053,  1.8226],\n",
      "         [ 0.3827, -0.1423,  0.4637,  ..., -1.8663, -0.3090,  1.6264],\n",
      "         [ 0.4837,  0.7676,  0.4224,  ..., -1.3742, -0.2670,  1.6772],\n",
      "         ...,\n",
      "         [ 0.4163,  0.6139,  0.7413,  ..., -1.8274, -0.2884,  1.7489],\n",
      "         [-0.2638,  1.0282,  1.0514,  ..., -1.6033,  0.3842,  2.4883],\n",
      "         [-0.2210,  0.9907,  0.6721,  ..., -1.7667,  0.4140,  1.7915]],\n",
      "\n",
      "        [[-0.4685,  0.7395,  0.2914,  ...,  0.1102,  0.2189, -0.8870],\n",
      "         [-0.4287,  0.5639, -0.9865,  ..., -1.0535,  0.5909, -0.6768],\n",
      "         [-1.0402,  0.3018,  1.2465,  ..., -0.6023,  0.4301,  0.8055],\n",
      "         ...,\n",
      "         [-0.7018, -0.4500,  2.2859,  ..., -0.3024, -0.0880,  0.5852],\n",
      "         [-0.1163, -0.3267,  0.3846,  ..., -2.8438, -0.1126, -0.2534],\n",
      "         [-0.6118,  0.1725,  2.8546,  ...,  0.5841,  0.3889,  0.7734]],\n",
      "\n",
      "        [[-1.6710,  0.1333,  0.6920,  ...,  0.5399,  0.3211,  0.9147],\n",
      "         [ 0.1459,  0.3971,  1.0924,  ..., -0.8594, -1.2453, -1.3900],\n",
      "         [-0.8387, -2.3047, -1.5467,  ..., -0.9615,  0.0479,  0.2591],\n",
      "         ...,\n",
      "         [ 0.0141, -1.2827,  2.3100,  ...,  0.1205,  2.6587,  0.8930],\n",
      "         [ 0.3342,  0.0069,  0.6134,  ..., -3.0220, -0.8093,  2.1623],\n",
      "         [-1.7218, -1.2623,  0.8420,  ..., -2.4856, -0.5293, -1.1222]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.8219,  0.9422, -0.9696,  ..., -0.7733, -0.3190,  1.8387],\n",
      "         [-2.6508,  1.0266, -0.9319,  ..., -0.7534,  0.1636,  1.5084],\n",
      "         [-2.2286, -0.1813, -0.8752,  ..., -0.2959, -0.0897,  1.7437],\n",
      "         ...,\n",
      "         [-2.1606,  1.2916, -0.9148,  ..., -1.1849, -0.0511,  1.6133],\n",
      "         [-1.9867,  1.3261, -1.2720,  ..., -0.4436, -0.1018,  2.0180],\n",
      "         [-2.1302,  1.0685, -1.1662,  ..., -0.2892,  0.0113,  1.8089]],\n",
      "\n",
      "        [[-1.6399,  1.1227,  0.2026,  ..., -0.7981, -0.2940,  1.3433],\n",
      "         [-1.8892,  1.1736, -1.0787,  ..., -0.6886, -0.0081,  1.6629],\n",
      "         [-1.6800,  1.0371, -1.3062,  ..., -0.4672,  0.0631,  1.6598],\n",
      "         ...,\n",
      "         [-1.5816,  1.2542, -0.9419,  ..., -0.8098, -0.4089,  1.4209],\n",
      "         [-1.7057,  0.9065, -0.9220,  ..., -1.0505, -0.0710,  1.4123],\n",
      "         [-2.0495,  1.0949, -1.3149,  ..., -0.4899,  0.0243,  2.1293]],\n",
      "\n",
      "        [[-1.4669,  0.7358, -0.8128,  ..., -0.2897,  0.0048,  1.5425],\n",
      "         [-1.4446,  0.8196, -0.6860,  ..., -0.3737, -0.1471,  1.7707],\n",
      "         [-1.7519,  0.6068, -0.7018,  ..., -1.5803, -0.0122,  1.6439],\n",
      "         ...,\n",
      "         [-1.9247,  0.3089, -0.6946,  ..., -0.3961, -0.4190,  2.3232],\n",
      "         [-1.4314,  0.7465, -1.0397,  ..., -0.5196,  0.0526,  1.7442],\n",
      "         [-1.1178,  0.2456, -0.8783,  ...,  0.0467,  0.1211,  1.7848]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0039,  0.0424, -0.0061,  ..., -0.0863,  0.1562,  0.0808],\n",
      "         [-0.0223, -0.0865, -0.0986,  ..., -0.0466,  0.0265,  0.1266],\n",
      "         [ 0.0131,  0.0389, -0.0547,  ..., -0.0103,  0.0977,  0.0187],\n",
      "         ...,\n",
      "         [ 0.0171, -0.0344, -0.0822,  ..., -0.0082,  0.0234,  0.0845],\n",
      "         [-0.0578, -0.0820, -0.0930,  ..., -0.1121,  0.1010,  0.0399],\n",
      "         [-0.0083, -0.0527, -0.0651,  ..., -0.0642,  0.0554,  0.0465]],\n",
      "\n",
      "        [[-0.0054,  0.0170, -0.0847,  ..., -0.0445,  0.1615, -0.0569],\n",
      "         [-0.0165,  0.0076, -0.1147,  ..., -0.0419,  0.1621, -0.0114],\n",
      "         [ 0.0226, -0.0186, -0.1182,  ...,  0.0099,  0.0913, -0.0313],\n",
      "         ...,\n",
      "         [-0.0109, -0.0291, -0.0705,  ..., -0.0588,  0.0696,  0.0800],\n",
      "         [ 0.0004, -0.0519, -0.0602,  ..., -0.0689,  0.0521,  0.0614],\n",
      "         [-0.0045,  0.0060, -0.0710,  ..., -0.0543,  0.0575,  0.0085]],\n",
      "\n",
      "        [[-0.1081,  0.0583, -0.0650,  ..., -0.1076,  0.0173,  0.0257],\n",
      "         [ 0.0398, -0.0419, -0.0614,  ..., -0.0542,  0.0685,  0.1258],\n",
      "         [ 0.0663,  0.0140, -0.0929,  ..., -0.0728,  0.0368,  0.0816],\n",
      "         ...,\n",
      "         [ 0.0261, -0.0165, -0.1235,  ...,  0.0794,  0.1632, -0.0092],\n",
      "         [-0.0066, -0.0550, -0.0973,  ..., -0.0639,  0.0356,  0.0243],\n",
      "         [-0.0174, -0.0433, -0.0304,  ..., -0.0762,  0.0790,  0.0973]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0880,  0.0056, -0.0652,  ...,  0.0163, -0.0108, -0.1201],\n",
      "         [ 0.0836,  0.1998, -0.0943,  ..., -0.0559,  0.0609,  0.1025],\n",
      "         [ 0.0248, -0.0338, -0.0674,  ..., -0.0431,  0.0468,  0.1097],\n",
      "         ...,\n",
      "         [-0.0202, -0.0061, -0.0853,  ..., -0.0164,  0.0573,  0.0559],\n",
      "         [-0.0051,  0.0132, -0.0262,  ..., -0.1032,  0.0304,  0.0501],\n",
      "         [ 0.0126, -0.0163, -0.0674,  ..., -0.0688,  0.0702,  0.0359]],\n",
      "\n",
      "        [[-0.0398,  0.0231, -0.0194,  ..., -0.0405,  0.0834,  0.0202],\n",
      "         [-0.0419, -0.0422, -0.0592,  ..., -0.0419, -0.0147,  0.0216],\n",
      "         [-0.1842,  0.1245, -0.0887,  ..., -0.0036,  0.2274,  0.1413],\n",
      "         ...,\n",
      "         [-0.0520,  0.1757, -0.2214,  ..., -0.0591,  0.1019,  0.1224],\n",
      "         [-0.0146, -0.0248, -0.0704,  ..., -0.0378,  0.0633,  0.0625],\n",
      "         [ 0.0007, -0.0089, -0.1186,  ..., -0.0753,  0.0425,  0.0400]],\n",
      "\n",
      "        [[-0.0107, -0.0126, -0.0762,  ..., -0.0537,  0.0775,  0.0626],\n",
      "         [ 0.0145,  0.1134, -0.1115,  ...,  0.0152,  0.1401,  0.1727],\n",
      "         [ 0.0032, -0.0472, -0.0767,  ..., -0.0517,  0.0509,  0.0274],\n",
      "         ...,\n",
      "         [-0.0024, -0.0214, -0.0712,  ..., -0.0172,  0.1651,  0.0791],\n",
      "         [-0.1227,  0.0058, -0.2168,  ...,  0.0889,  0.1154,  0.1422],\n",
      "         [ 0.0949,  0.3551, -0.1679,  ..., -0.0553,  0.1945,  0.1646]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"Tensor\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1014\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m196\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsz\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatchsz\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m196\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/work/ummt/Core model files/Modele_decodeur_maison.py:93\u001b[0m, in \u001b[0;36mModèle.forward\u001b[0;34m(self, text_input, image_bool, image_input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text_encoded\u001b[38;5;241m.\u001b[39mshape, image_encoded\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     91\u001b[0m     x \u001b[38;5;241m=\u001b[39m [text_encoded, image_encoded]\n\u001b[0;32m---> 93\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositional_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# Pass through the decoder\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/transformer.py:333\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    330\u001b[0m output \u001b[38;5;241m=\u001b[39m tgt\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 333\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/work/ummt/Core model files/NewDecoderLayer.py:40\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[0;34m(self, x, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m     38\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_1(text)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(x2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_1(x2, x2, x2, tgt_mask)[\u001b[38;5;241m0\u001b[39m]),x)\n\u001b[0;32m---> 40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Here, att1 returns a tuple, the first being the result, the second being the attention weights\u001b[39;00m\n\u001b[1;32m     42\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_2(x)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"Tensor\") to list"
     ]
    }
   ],
   "source": [
    "output = model_fr(data_text, True, torch.from_numpy(val_features.reshape(1014,1024,196)[:1000].reshape(1000//batchsz ,1024,batchsz , 196)[0]).to(device= device, dtype = torch.float32)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
