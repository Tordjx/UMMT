{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb10bae-68df-4d91-9e10-2cecaf169e71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/mamba/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/mamba/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "#mc cp s3/tordjx ummt --recursive\n",
    "# watch -n 0.5 nvidia-smi\n",
    "# ATTE?TION A LA PIPELINE BATCHIFYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7ee3bb-7c9c-47e3-ae7f-064be78e7002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Texts\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m tokenized_fr,tokenized_en, vocab_fr,vocab_en \u001b[38;5;241m=\u001b[39m \u001b[43mget_train_data_nouveau\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#Data non batchés\u001b[39;00m\n\u001b[1;32m     12\u001b[0m n_token_fr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(vocab_fr\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/work/ummt/Core model files/Pipeline.py:54\u001b[0m, in \u001b[0;36mget_train_data_nouveau\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m     44\u001b[0m             vocab_fr[mot] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(vocab_fr\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# tokenized_fr = torch.zeros( len(train_data_fr),longueur_max)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# tokenized_en = torch.zeros( len(train_data_en),longueur_max)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# for i in range(len(train_data_fr)) : \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# batched_fr = torch.tensor([[[vocab_fr[train_data_fr[k*batch_size+j][i]] for i in range (longueur_max)] for j in range(batch_size)] for k in range(len(train_data_fr)//batch_size)]).to(device=device, dtype= torch.long)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# batched_en = torch.tensor([[[vocab_en[train_data_en[k*batch_size+j][i]] for i in range (longueur_max)] for j in range(batch_size)] for k in range(len(train_data_en)//batch_size)]).to(device=device, dtype= torch.long)\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m tokenized_fr \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvocab_fr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmot\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_data_fr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m tokenized_en \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[vocab_en[mot] \u001b[38;5;28;01mfor\u001b[39;00m mot \u001b[38;5;129;01min\u001b[39;00m phrase] \u001b[38;5;28;01mfor\u001b[39;00m phrase \u001b[38;5;129;01min\u001b[39;00m train_data_en])\u001b[38;5;241m.\u001b[39mto(device \u001b[38;5;241m=\u001b[39m device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#En sortie : les données tokenizées non batchées\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from Modele_decodeur_maison import *\n",
    "from Pipeline import *\n",
    "from Trainer import * \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 32\n",
    "\n",
    "# Texts\n",
    "tokenized_fr,tokenized_en, vocab_fr,vocab_en = get_train_data_nouveau(batch_size)\n",
    "#Data non batchés\n",
    "n_token_fr = len(vocab_fr.keys())\n",
    "n_token_en = len(vocab_en.keys())\n",
    "\n",
    "inv_map_en = {v: k for k, v in vocab_en.items()}\n",
    "inv_map_fr = {v: k for k, v in vocab_fr.items()}\n",
    "\n",
    "n_head = 16\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 4096\n",
    "dropout = 0.1\n",
    "activation = nn.Softmax(dim=2)\n",
    "embedding_dim = 1024\n",
    "\n",
    "model_fr = Modèle(n_token_fr,embedding_dim,n_head, num_encoder_layers,num_decoder_layers,dim_feedforward,dropout,activation,vocab_fr[\"TOKEN_VIDE\"],vocab_fr[\"DEBUT_DE_PHRASE\"],vocab_fr[\"FIN_DE_PHRASE\"]).to(device)\n",
    "model_en = Modèle(n_token_en,embedding_dim,n_head, num_encoder_layers,num_decoder_layers,dim_feedforward,dropout,activation,vocab_en[\"TOKEN_VIDE\"],vocab_en[\"DEBUT_DE_PHRASE\"],vocab_en[\"FIN_DE_PHRASE\"]).to(device)\n",
    "\n",
    "#IF WE WANT TO LOAD PREVIOUSLY TRAINED MODEL\n",
    "# model_en.load_state_dict(torch.load(\"tordjx/model_en\"))\n",
    "# model_fr.load_state_dict(torch.load(\"tordjx/model_fr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604d4a2-4579-4027-a9be-42ba3d74eca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_features  = np.load(fs.open('tordjx/val-resnet50-res4frelu.npy'))\n",
    "# train_features  = np.load(fs.open('tordjx/train-resnet50-res4frelu.npy'))\n",
    "# val_features = np.load(\"C:/Users/lucas/Desktop/val-resnet50-res4frelu.npy\")\n",
    "# val_features = np.load(\"C:/Users/lucas/Desktop/val-resnet50-res4frelu.npy\")\n",
    "train_features  = np.load(\"tordjx/train-resnet50-res4frelu.npy\")\n",
    "val_features = np.load(\"tordjx/val-resnet50-res4frelu.npy\")\n",
    "train_features = torch.from_numpy(train_features)\n",
    "val_features = torch.from_numpy(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493cdfe-c6fe-42b4-9f7a-e89c4df97f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_fr = [tokenized_fr, train_features]\n",
    "train_data_en = [tokenized_en, train_features]\n",
    "mixed_train(model_fr,model_en,train_data_fr,train_data_en,500,batch_size, True,[1/2,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033da8a6-1d98-4eea-be9a-ba67221f6780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def moving_average(a, n=100,tail = 0) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return (ret[n - 1:] / n)[tail:]\n",
    "\n",
    "plt.plot(moving_average(model_fr.loss_list))\n",
    "plt.plot(moving_average(model_en.loss_list))\n",
    "# plt.plot(model_en.loss_list)\n",
    "print(len(model_fr.loss_list)/(29000/batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d22bad-1b01-473e-aac1-4527dbb13dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5): #nhead\n",
    "    for j in range(4):#encoderdecoder layer\n",
    "        for k in range(13,17): #dim feedforward\n",
    "            for l in range (8,11): \n",
    "                n_head = 2**i\n",
    "                num_encoder_layers = 2**j\n",
    "                num_decoder_layers = 2**j\n",
    "                dim_feedforward = 2**k\n",
    "                embedding_dim = 2**l\n",
    "                model_fr = Modèle(n_token_fr,embedding_dim,n_head, num_encoder_layers,num_decoder_layers,dim_feedforward,dropout,activation,vocab_fr[\"TOKEN_VIDE\"],vocab_fr[\"DEBUT_DE_PHRASE\"],vocab_fr[\"FIN_DE_PHRASE\"]).to(device)\n",
    "                model_en = Modèle(n_token_en,embedding_dim,n_head, num_encoder_layers,num_decoder_layers,dim_feedforward,dropout,activation,vocab_en[\"TOKEN_VIDE\"],vocab_en[\"DEBUT_DE_PHRASE\"],vocab_en[\"FIN_DE_PHRASE\"]).to(device)\n",
    "                mixed_train(model_fr,model_en,train_data_fr,train_data_en,15,batch_size, True,[1/2,1])\n",
    "                plt.plot(moving_average(model_fr.loss_list), label = \"nhead \"+str(2**i) +\"num_encoderdecoder_layers \"+str(2**j) +\"dim_feedforward \"+str(2**k) +\"dim_embedding \"+str(2**l) )\n",
    "                plt.plot(moving_average(model_en.loss_list), label = \"nhead \"+str(2**i) +\"num_encoderdecoder_layers \"+str(2**j) +\"dim_feedforward \"+str(2**k) +\"dim_embedding \"+str(2**l) )\n",
    "                print(\"nhead \"+str(2**i) +\"num_encoderdecoder_layers \"+str(2**j) +\"dim_feedforward \"+str(2**k) +\"dim_embedding \"+str(2**l))\n",
    "                plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af80f3d-53f1-4fe7-9aa1-1868350791a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model_fr.state_dict(), \"tordjx/model_fr\")\n",
    "torch.save(model_en.state_dict(), \"tordjx/model_en\")\n",
    "import os\n",
    "import s3fs\n",
    "!pip install pandas\n",
    "import pandas\n",
    "# Create filesystem object\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "fs.upload(\"tordjx/model_fr\",\"tordjx/model_fr\")\n",
    "fs.upload(\"tordjx/model_en\",\"tordjx/model_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927b652e-793c-439a-9d27-a9a65e88d9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "train_data_fr = [tokenized_fr, train_features]\n",
    "train_data_en = [tokenized_en, train_features]\n",
    "def tensor_to_sentence(output,inv_dic):\n",
    "    result = [inv_dic[int(x)] for x in output]\n",
    "    sentence = \"\"\n",
    "    for word in result : \n",
    "        if word == \"DEBUT_DE_PHRASE\" :\n",
    "            pass\n",
    "        elif '@@' in word: \n",
    "            sentence+=word[:-2]\n",
    "        elif word == \"FIN_DE_PHRASE\" :\n",
    "            break \n",
    "        \n",
    "        else :\n",
    "            sentence+=word +\" \"\n",
    "    return sentence\n",
    "\n",
    "def traduit(model_A,model_B,data, inv_map,image_bool):\n",
    "    model_en.eval()\n",
    "    model_fr.eval()\n",
    "    if image_bool : \n",
    "        data,features= data\n",
    "    output = torch.argmax(cycle_consistent_forward(model_A,model_B,data,features, True),dim = 2)[j]\n",
    "    return tensor_to_sentence(output.view(-1),inv_map)\n",
    "\n",
    "\n",
    "\n",
    "def donne_random():\n",
    "    i = np.random.randint(len(tokenized_en)//batch_size)\n",
    "    j = np.random.randint(batch_size)\n",
    "    batched_data=batchify(train_data_en,batch_size,True)\n",
    "    data,features = batched_data\n",
    "    return data[i],features[i]\n",
    "\n",
    "text,features = donne_random()\n",
    "features = features.to(device,dtype=torch.float32)\n",
    "data = [text,features]\n",
    "for i in range(10):\n",
    "    j = np.random.randint(batch_size)\n",
    "    print(\"Phrase à traduire : \\n\" + tensor_to_sentence(text[j],inv_map_en)+ \"\\n Phrase traduite : \\n \"+ traduit(model_en,model_fr,data, inv_map_fr,True))\n",
    "\n",
    "\n",
    "#%%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
